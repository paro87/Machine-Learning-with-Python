{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before submitting\n",
    "1. Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel\\Restart) and then **run all cells** (in the menubar, select Cell\\Run All).\n",
    "\n",
    "2. Make sure that no assertions fail or exceptions occur, otherwise points will be subtracted.\\n\",\n",
    "\n",
    "3. After you submit the notebook more tests will be run on your code. The fact that no assertions fail on your computer localy does not guarantee that you completed the exercise correctly.\n",
    "\n",
    "4. Please submit only the `*.ipynb` file.\n",
    "\n",
    "5. Make sure you fill in any place that says `YOUR CODE HERE` or \\\"YOUR ANSWER HERE\\\". Edit only between `YOUR CODE HERE` and `END YOUR CODE`.\n",
    "\n",
    "6. Make sure to use Python 3.6 at least."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if sys.version_info < (3, 6):\n",
    "    print(\"You are not using a modern enough version of Python. \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "113c9d07f3d5ab70c7b61d75a157c639",
     "grade": false,
     "grade_id": "cell-78cd1baff9635896",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Exercise Sheet 3: Advanced Numpy\n",
    "\n",
    "In the third exercise sheet we will work on advanced numpy topics and application on machine learning tasks. You will implement the complete datascience pipline, starting with data loading, plotting and data exploration, and finally implementing a machine learning model and applying it on the data.\n",
    "\n",
    "For each exercise there will be a maximum number of loops allowed. If your function contains more loops than allowed, you will be notified during the function definition, and the function will automatically fail in the hidden tests. \n",
    "\n",
    "For technical reasons the following functions are **banned** throughout the notebook.\n",
    "\n",
    "- map\n",
    "- sum\n",
    "- filter\n",
    "- np.vectorize\n",
    "- np.fromiter\n",
    "- np.fromfunction\n",
    "- np.apply_along_axis\n",
    "\n",
    "If you use one of these functions in your submissions it will **automatically fail**.\n",
    "\n",
    "**Important:** \n",
    "   \n",
    "- Execute every cell in the notebook. You may also try to restart your kernel and execute all cells, in case something went wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad643ef847ec5ae8d0d3c72f5722e3e1",
     "grade": true,
     "grade_id": "cell-bfc2ecb9fb8fec38",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# EXECUTE the setup cell !\n",
    "\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from unittest import TestCase\n",
    "\n",
    "t = TestCase()\n",
    "from minified import max_allowed_loops, no_imports\n",
    "\n",
    "from IPython.display import Markdown as md\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "65e798c24c99aab03320d8630b246394",
     "grade": false,
     "grade_id": "cell-cb21008c94638bf3",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Exercise 1.1: ( 8 points ) \n",
    "\n",
    "Read the data from the file data.csv and save it in a dictionary. The letters in data.csv are the assigned labels and their corresponding datapoints. Each datapoint is two-dimensional and consists of the given x- and y-values. Return a dictionary with the letters/labels as keys. The value assigned to each key should be a list of x- and y-values. \n",
    "\n",
    "* Do not forget to cast the vaules to float.\n",
    "\n",
    "<!-- * TODO: Is the list allowed to be two dimensional? -->\n",
    "\n",
    "* Number of loops allowed in this exercise: 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c1958399d305e98593b99d1281e9ee3c",
     "grade": false,
     "grade_id": "cell-8274a5d6206df5cb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "@no_imports\n",
    "@max_allowed_loops(1)\n",
    "def read_from_file(file: str = \"data.csv\") -> Dict[str, List[Tuple[float, float]]]:\n",
    "    \"\"\"\n",
    "    Opens a csv file and parses it line by line. Each line consists of a label and two\n",
    "    data dimensions. The function returns a dictionary where each key is a label and\n",
    "    the value is a list of all the datapoints that have that label. Each datapoint\n",
    "    is represented by a pair (2-element tuple) of floats.\n",
    "\n",
    "    Args:\n",
    "        file (str, optional): The path to the file to open and parse. Defaults to\n",
    "        \"data.csv\".\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, List[Tuple[float, float]]]: The parsed contents of the csv file\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError(\"Relplace this line with your code\")\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d727daa322eb0f03830a1e0ef08f7153",
     "grade": true,
     "grade_id": "cell-9df4522a7b9adedd",
     "locked": true,
     "points": 8,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "tiny_result = read_from_file(file=\"tiny.csv\")\n",
    "print(\"tiny_result\", tiny_result)\n",
    "tiny_expected = {\"A\": [(0.8, 0.9), (0.2, 0.3)], \"B\": [(0.9, 0.1)], \"C\": [(2.0, 4.0)]}\n",
    "t.assertEqual(tiny_result, tiny_expected)\n",
    "\n",
    "D = read_from_file(file=\"data.csv\")\n",
    "print(f\"Keys of D: {D.keys()}\", end=\"\\n\\n\")\n",
    "for k, v in D.items():\n",
    "    print(f\"{len(v)} datapoints were assigned the label {k}\")\n",
    "\n",
    "# Test All types\n",
    "t.assertIsInstance(D, dict)\n",
    "for d in D:\n",
    "    t.assertIsInstance(d, str)\n",
    "    t.assertIsInstance(D[d], list)\n",
    "    for el in D[d]:\n",
    "        t.assertIsInstance(el, tuple)\n",
    "        t.assertIsInstance(el[0], float)\n",
    "        t.assertIsInstance(el[1], float)\n",
    "\n",
    "letters = \"MNU\"\n",
    "t.assertEqual(set(D.keys()), set(letters))\n",
    "t.assertTrue(all(len(v) > 99 for v in D.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "27966df7a375174efa2f52ae04e70601",
     "grade": true,
     "grade_id": "cell-c457103f016f505a",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8df2e148b6dd85e05daec2403fa3f47d",
     "grade": false,
     "grade_id": "cell-3defd523da9ddb93",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 1.2: ( 5 Pts )\n",
    "\n",
    "Use numpy to stack all of the $N$ datapoints from the dictionary into one matrix $X$, containing the data.\n",
    "\n",
    "Additionally, create one array $y$ with the corresponding integer labels. \n",
    "\n",
    "Each datapoint $x_i \\in X, \\> i = \\overline{1..N}$ is of dimension $D=2$. The label assigned to a datapoint has to be a positive integer. Every letter-label should map to one integer-label in $y$ accordingly.\n",
    "\n",
    "Maping example: $A \\rightarrow 0,\\> C \\rightarrow 1,\\> K \\rightarrow 2, ...$ (The order of the keys/labels defines the numeric label. The first key is mapped to 0 and so on.)\n",
    "\n",
    "* Dataset $X$: $$\\Large X \\in \\mathbb{R}^{(N, D)}$$\n",
    "* Labels $y$: $$\\Large y \\in \\mathbb{N}^{(N,)} $$\n",
    "\n",
    "* Number of loops allowed in this exercise: 1 (for iterating over the keys of the dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "28c281c57de6ff9b713018e04b36a622",
     "grade": true,
     "grade_id": "cell-de6d83d74d8cd21b",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dc1d1eac5c032bafadafedb0494ced75",
     "grade": false,
     "grade_id": "cell-fd7454f24dc32a3e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "@no_imports\n",
    "@max_allowed_loops(1)\n",
    "def stack_data(\n",
    "    D: Dict[str, List[Tuple[float, float]]]\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Convert a dictionary dataset into a two arrays of data and labels. The dictionary \n",
    "    keys represent the labels and the value mapped to each key is a list that \n",
    "    contains all the datapoints belonging to that label. The output are two arrays \n",
    "    the first is the datapoints in a single 2d array and a vector of intergers \n",
    "    with the coresponding label for each datapoint. The order of the datapoints is\n",
    "    preserved according to the order in the dictionary and the lists.\n",
    "\n",
    "    The labels are converted from a string to a unique int.\n",
    "    \n",
    "    The datapoints are entered in the same order as the keys in the `D`. First\n",
    "    all the datapoints of the first key are entered then the second and so on.\n",
    "    Within one label order also remains.\n",
    "    \n",
    "    Args:\n",
    "        D (Dict[str, List[Tuple[float, float]]]): The dictionary that should be stacked\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.ndarray]: The two output arrays. The first is a \n",
    "        float-matrix containing all the datapoints. The second is an int-vector \n",
    "        containing the labels for each datapoint\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError(\"Relplace this line with your code\")\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9effbe8f9b2c4e216b2af590cc2bd6c0",
     "grade": true,
     "grade_id": "cell-61647bd7c0adf999",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tiny_expected_X, tiny_expected_y = (\n",
    "    np.array([[0.0, 0.1], [0.9, 0.7], [0.8, 0.3],]),\n",
    "    np.array([0, 1, 1]),\n",
    ")\n",
    "tiny_result_X, tiny_result_y = stack_data(\n",
    "    {\"B\": [(0.0, 0.1)], \"A\": [(0.9, 0.7), (0.8, 0.3)]}\n",
    ")\n",
    "print(tiny_result_X, tiny_result_y)\n",
    "np.testing.assert_allclose(tiny_expected_X, tiny_result_X)\n",
    "np.testing.assert_allclose(tiny_expected_y, tiny_result_y)\n",
    "\n",
    "X, y = stack_data(D)\n",
    "print(X.shape, y.shape)\n",
    "print(X.dtype, y.dtype)\n",
    "\n",
    "expected_len = sum(len(x) for x in D.values())\n",
    "print(f\"Expected length for X, y: {expected_len}\")\n",
    "\n",
    "t.assertEqual(X.shape, (expected_len, 2))\n",
    "t.assertEqual(y.shape, (expected_len,))\n",
    "\n",
    "t.assertEqual(X.dtype, np.float64)\n",
    "t.assertEqual(y.dtype, np.int64)\n",
    "\n",
    "t.assertEqual(set(y), set(range(len(D))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b3ae101988d33df866f43688f03e1f4",
     "grade": true,
     "grade_id": "cell-c3d938239f97bc3e",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3960ef5c00a1b4899058e0192c6e50f3",
     "grade": false,
     "grade_id": "cell-d1207f635471e8b8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 1.3: ( 4 Pts )\n",
    "\n",
    "Write a function that returns a list of all $k$ clusters $C$. A cluster $C_k$ is composed of every datapoint $X_i$ assigned with the label $k$. There are as many clusters $C_k$ as there are unique labels in $y$.\n",
    "\n",
    "\n",
    "$$\\Large{\\mathcal{C} = \\{ C_1, C_2, \\cdots, C_k \\},\\quad k = \\overline{1..K}}$$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\\Large C_k \\in \\mathbb{R}^{(N_k, D)}$$\n",
    "\n",
    "* Number of loops allowed in this exercise: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f5d024cd5a59e00fca66b1ddf6acf7a1",
     "grade": false,
     "grade_id": "cell-a98a62f606b67bc3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "@no_imports\n",
    "@max_allowed_loops(1)\n",
    "def get_clusters(X: np.ndarray, y: np.ndarray) -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Receives a labeled dataset and splits the datapoints according to label\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): The dataset\n",
    "        y (np.ndarray): The label for each point in the dataset\n",
    "\n",
    "    Returns:\n",
    "        List[np.ndarray]: A list of arrays where the elements of each array\n",
    "        are datapoints belonging to the label at that index.\n",
    "        \n",
    "    Example:\n",
    "    >>> get_clusters(\n",
    "            np.array([[0.8, 0.7], [0, 0.4], [0.3, 0.1]]), \n",
    "            np.array([0,1,0])\n",
    "        )\n",
    "    >>> [array([[0.8, 0.7],[0.3, 0.1]]), \n",
    "         array([[0. , 0.4]])]\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError(\"Relplace this line with your code\")\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6d91827d68720b1c6e6169ceb0ff3ce1",
     "grade": true,
     "grade_id": "cell-651e8faf9efa1d69",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tiny_result = get_clusters(\n",
    "    np.array([[0.8, 0.7], [0, 0.4], [0.3, 0.1]]), np.array([0, 1, 0])\n",
    ")\n",
    "print(tiny_result)\n",
    "tiny_expected = [np.array([[0.8, 0.7], [0.3, 0.1]]), np.array([[0.0, 0.4]])]\n",
    "for r, e in zip(tiny_result, tiny_expected):\n",
    "    np.testing.assert_allclose(r, e)\n",
    "\n",
    "clusters = get_clusters(X, y)\n",
    "# output is list\n",
    "t.assertIsInstance(clusters, List)\n",
    "t.assertEqual(len(letters), len(clusters))\n",
    "\n",
    "# all elements are arrays\n",
    "for el in clusters:\n",
    "    t.assertIsInstance(el, np.ndarray)\n",
    "\n",
    "t.assertEqual(sum(map(len, clusters)), len(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e0a6f7f379091b33501ace87eea56fa8",
     "grade": true,
     "grade_id": "cell-c18b7a483384b26f",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.4: ( 8 Pts )\n",
    "\n",
    "Split the data $X$ into training and testing data.\n",
    "\n",
    "* Return a list of clusters for training and a list of cluster for testing.\n",
    "\n",
    "\n",
    "* Utilize the function __train_test_idxs(L, test_ratio)__ from utils to split the data.\n",
    "\n",
    "- The train-test ratio should be 80-20\n",
    "\n",
    "* Use the function implemented in Exercise 1.3 __get_clusters(X,y)__ to get the clusters.\n",
    "\n",
    "\n",
    "* Number of loops allowed in this exercise: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import train_test_idxs\n",
    "\n",
    "print(\"train_test_idxs specification:\\n\", train_test_idxs.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7e65acaecea4c9938ac7197f396fe503",
     "grade": false,
     "grade_id": "cell-9a3e3b8eb462afbc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "@no_imports\n",
    "@max_allowed_loops(0)\n",
    "def split(X: np.ndarray, y: np.ndarray) -> Tuple[List[np.ndarray], List[np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Split the data into train and test sets. The training and test set are clustered by\n",
    "    label using `get_clusters`. The size of the training set is 80% of the whole\n",
    "    dataset\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): The dataset (2d)\n",
    "        y (np.ndarray): The labels (1d)\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[np.ndarray], List[np.ndarray]]: The clustered training and \n",
    "        testset\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError(\"Relplace this line with your code\")\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "\n",
    "    return tr_clusters, te_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "98495e228e7fad16417c8d4d9b786da7",
     "grade": true,
     "grade_id": "cell-ead3f23734e9cde2",
     "locked": true,
     "points": 8,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "output = split(X, y)\n",
    "tr_clusters, te_clusters = output\n",
    "t.assertIsInstance(output, Tuple)\n",
    "t.assertIsInstance(tr_clusters, List)\n",
    "t.assertIsInstance(te_clusters, List)\n",
    "\n",
    "t.assertEqual(len(tr_clusters), len(te_clusters))\n",
    "t.assertEqual(len(tr_clusters), len(letters))\n",
    "t.assertEqual(len(te_clusters), len(letters))\n",
    "\n",
    "for el in tr_clusters + te_clusters:\n",
    "    t.assertIsInstance(el, np.ndarray)\n",
    "\n",
    "\n",
    "n_in_train = sum(map(len, tr_clusters))\n",
    "n_in_test = sum(map(len, te_clusters))\n",
    "t.assertEqual(n_in_train + n_in_test, len(X))\n",
    "\n",
    "percent_train = n_in_train / len(X)\n",
    "t.assertGreaterEqual(percent_train, 0.78)\n",
    "t.assertLessEqual(percent_train, 0.82)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0efa5504a9a13bdc4a922cac5965e570",
     "grade": true,
     "grade_id": "cell-1b9f3d481003661f",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.5:  (5 Pts )\n",
    "\n",
    "Compute the mean $\\mu_k$ of each cluster $C_k$. Return a list of all cluster means $\\mu$.\n",
    "\n",
    "\n",
    "$$\\Large{\\mu = \\{ \\mu_1, \\mu_2, \\cdots, \\mu_k \\},\\quad k = \\overline{1..K}}$$\n",
    "\n",
    "\n",
    "\n",
    "* Number of elements in a cluster $k$:\n",
    "$$\\Large{N_k = | C_k |, \\quad C_k \\in \\mathbb{R}^{(N_k, D)}}$$\n",
    "\n",
    "\n",
    "\n",
    "* The $k$-th cluster mean $\\mu_k$:\n",
    "$$\\Large{ \\mu_k = \\frac{1}{N_k}\\sum_{x_i \\in C_k} x_i }$$\n",
    "\n",
    "\n",
    "\n",
    "* Number of loops allowed in this exercise: 1 (to iterate over the clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "de25614939da189812699b4266df8d19",
     "grade": false,
     "grade_id": "cell-163f018544e3c548",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "@no_imports\n",
    "@max_allowed_loops(1)\n",
    "def calc_means(clusters: List[np.ndarray]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    For a collections of clusters calculate the mean for each cluster\n",
    "    \n",
    "    Args:\n",
    "        clusters (List[np.ndarray]): A list of 2d arrays\n",
    "        \n",
    "    Returns:\n",
    "        List[np.ndarray]: A matrix where each row represents a mean of a cluster\n",
    "        \n",
    "    Example: \n",
    "        >>> tiny_clusters = [\n",
    "            np.array([[0.2, 0.3], [0.1, 0.2]]),\n",
    "            np.array([[0.8, 0.9], [0.7, 0.5], [0.6, 0.7]]),\n",
    "        ]\n",
    "        >>> calc_means(tiny_clusters)\n",
    "        [array([0.15, 0.25]), array([0.7,0.7])]\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError(\"Relplace this line with your code\")\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b2631e47660ea796a0898e3123de86c4",
     "grade": true,
     "grade_id": "cell-417ff17a7f89706b",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tiny_clusters = [\n",
    "    np.array([[0.2, 0.3], [0.1, 0.2]]),\n",
    "    np.array([[0.8, 0.9], [0.7, 0.5], [0.6, 0.7]]),\n",
    "]\n",
    "tiny_result = calc_means(tiny_clusters)\n",
    "print(tiny_result, end=\"\\n\\n\")\n",
    "tiny_expected = np.array([[0.15, 0.25], [0.7, 0.7]])\n",
    "np.testing.assert_allclose(tiny_result, tiny_expected)\n",
    "\n",
    "means = calc_means(tr_clusters)\n",
    "print(means)\n",
    "t.assertIsInstance(means, np.ndarray)\n",
    "t.assertEqual(means.shape, (len(letters), 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9d6764c554197a0bb582cce43f3cbfc9",
     "grade": true,
     "grade_id": "cell-a78860f98dee20d8",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "97de2be6f62c2d7ae1128f5e16d6ff75",
     "grade": false,
     "grade_id": "cell-b0c8b58fdd2f7385",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Exercise 2.1: Scatter plot of clusters ( 15 points )\n",
    "\n",
    "- Create a scatter plot of size 8x8. \n",
    "\n",
    "- Plot each datapoint of a cluster $x_{ik} \\in  C_k$ as dots with an alpha value of 0.6 and a label. \n",
    "\n",
    "- The plot-label should contain both the cluster's letter-label as well as its integer-label. \n",
    "\n",
    "- Further, plot the cluster's mean $\\mu_k$ as a red cross of size 7. The plot should also have a label for each cluster's mean, giving information on its exact coordinates. \n",
    "\n",
    "- The title of the plot should be _'Scatter plot of the clusters'_ in fontsize 20.\n",
    "\n",
    "* Label for the scatter plots example: _A = 0_\n",
    "* Label for the cluster means example (use LaTeX): _$\\mu_A:$[1.23  0.56]_\n",
    "\n",
    "- If the mean of each cluster is not provided, use `calc_means(clusters)` to calculate the means.\n",
    "\n",
    "\n",
    "* Number of loops allowed in this exercise: 1 (for iteration over the clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "56918e905fd6f1ee3eb83c46745bec37",
     "grade": false,
     "grade_id": "cell-cf145588f2264965",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a3a72c6e3fddbe6130c042b1041146a9",
     "grade": true,
     "grade_id": "cell-1c20dd9d88bafdc1",
     "locked": false,
     "points": 15,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "@no_imports\n",
    "def plot_scatter_and_mean(\n",
    "    clusters: List[np.ndarray],\n",
    "    letters: List[str],\n",
    "    means: Optional[List[np.ndarray]] = None,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Create a scatter plot visulizing each cluster and its mean\n",
    "    \n",
    "    Args:\n",
    "        clusters (List[np.ndarray]): A list containing arrrays representing \n",
    "        each cluster\n",
    "        letters (List[str]): The \"name\" of each cluster\n",
    "        means (Optional[List[np.ndarray]]): The mean of each cluster. If not\n",
    "        provided the mean of each cluster in `clusters` should be calculated and \n",
    "        used\n",
    "        \n",
    "    \"\"\"\n",
    "    assert len(letters) == len(clusters)\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError(\"Relplace this line with your code\")\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1c5cbcfacd39d6d31ff7dbafc0db52b5",
     "grade": false,
     "grade_id": "cell-0c2f0435cc96e58a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plot_scatter_and_mean(tr_clusters, letters, means=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "35fee2e02396faa059c0daa69a8c7bb6",
     "grade": false,
     "grade_id": "cell-afffe3532473fb6d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 2.2: (15 points)\n",
    "\n",
    " - To make it easier to visually analyse the the differences between clusters, the data can be projected onto an axis. Plot a histrogram for the projection onto the given axis. \n",
    " \n",
    " - The histogram should have 30 bins, be 50% transparent and labeled. The area under the histogram should be normalized and sum to 1 to represent a proper distribution. It can be done by setting the corresponding parameter.  - The bars width should have 4/5 of the bins width.\n",
    "\n",
    "\n",
    "- Create a scatter plot of size 14x5.\n",
    "* Plot the mean of each cluster as a vertical, dashed, red line.\n",
    "* Label for the histograms example: _A_\n",
    "* The title of the plot should be dynamic, have a font size of 20 and explain the axis of the projection, e.g. \"Projection to axis 0 histogramm plot\" or \"Projection to axis 1 histogramm plot\", depending on the axis.\n",
    "\n",
    "\n",
    "* Number of loops allowed in this exercise: 1 (to iterate over the clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "77f9b81f754652ad530f9920dd16421e",
     "grade": true,
     "grade_id": "cell-3bb90069425adc8b",
     "locked": false,
     "points": 15,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "@no_imports\n",
    "def plot_projection(\n",
    "    clusters: List[np.ndarray], letters: List[str], means: np.ndarray, axis: int = 0\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot a histogram of the dimension provided in `axis`\n",
    "    \n",
    "    Args:\n",
    "        clusters (List[np.ndarray]): The clusters from which to create the historgram\n",
    "        letters (List[str]): The string representation of each class\n",
    "        means (np.ndarray): The mean of each class\n",
    "        axis (int): The axis from which to create the historgram. Defaults to 0.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError(\"Relplace this line with your code\")\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1640acd2896aa489504d6eb3122bf710",
     "grade": false,
     "grade_id": "cell-b7631b4add7c4883",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plot_projection(tr_clusters, letters, means, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d5b3b41b07567164353d22d04ca8c5df",
     "grade": false,
     "grade_id": "cell-786fa6dbff5fb0a3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 3.1: (8 points)\n",
    "\n",
    "Compute the within cluster covariance $S_w$ to further analyse the distribution of the data in the clusters. Sum up the covariance matrices of each cluster to get the one average within cluster corvariance matrix. **This is shown in the formula below.** Covariance matrices describe the relationship between the x and y dimensions of the data.\n",
    "\n",
    "$$\\boxed{\\Large{S_w  = \\sum_{k=1}^K \\sum_{x_i \\in C_k} (x_i - \\mu_k) (x_i - \\mu_k)^{\\top}}, \\quad S_w \\in \\mathbb{R}^{(D, D)}}$$\n",
    "\n",
    "\n",
    "* Reminder: Data $C$ is a set of clusters $C_k$, where $K$ is the total number of clusters. $${\\mathcal{C} = \\{ C_1, C_2, \\cdots, C_k \\},\\quad k = \\overline{1..K}}$$\n",
    "\n",
    "* Number of elements in a cluster $k$: $${N_k = | C_k |, \\quad C_k \\in \\mathbb{R}^{(N_k, D)}}$$\n",
    "<br>\n",
    "\n",
    "* $k$-th cluster mean $\\mu_k$: $${ \\mu_k = \\frac{1}{N_k}\\sum_{x_i \\in C_k} x_i }$$\n",
    "\n",
    "* Number of loops allowed in this exercise: 1 (to iterate over the clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "383820c9beef27f163c5c7bf28cdcc33",
     "grade": false,
     "grade_id": "cell-8a88e196dfbf93b1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "@no_imports\n",
    "@max_allowed_loops(1)\n",
    "def within_cluster_cov(clusters: List[np.ndarray]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate the within class covariance for a collection of clusters\n",
    "    \n",
    "    Args:\n",
    "        clusters (List[np.ndarray]): A list of clusters each consisting of \n",
    "        an array of datapoints\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: The within cluster covariance \n",
    "        \n",
    "    Example: \n",
    "        >>> within_cluster_cov(\n",
    "            [array([[0.2, 0.3], [0.1, 0.2]]), array([[0.8, 0.9], [0.7, 0.5], [0.6, 0.7]])]\n",
    "        )\n",
    "        >>> array([[0.025, 0.025],\n",
    "                   [0.025, 0.085]])\n",
    "    \"\"\"\n",
    "    d = clusters[0].shape[1]\n",
    "    S_w = np.zeros((d, d))\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError(\"Relplace this line with your code\")\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f2d45e73032f45266d0e35663e1daddc",
     "grade": true,
     "grade_id": "cell-ca257344ee385a22",
     "locked": true,
     "points": 8,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tiny_clusters = [\n",
    "    np.array([[0.2, 0.3], [0.1, 0.2]]),\n",
    "    np.array([[0.8, 0.9], [0.7, 0.5], [0.6, 0.7]]),\n",
    "]\n",
    "tiny_expected = np.array([[0.025, 0.025], [0.025, 0.085]])\n",
    "tiny_result = within_cluster_cov(tiny_clusters)\n",
    "print(tiny_result)\n",
    "np.testing.assert_allclose(tiny_expected, tiny_result)\n",
    "\n",
    "S_w = within_cluster_cov(tr_clusters)\n",
    "print(S_w)\n",
    "t.assertIsInstance(S_w, np.ndarray)\n",
    "t.assertEqual(S_w.shape, (2, 2))\n",
    "\n",
    "# check if symmetric\n",
    "np.testing.assert_allclose(S_w, S_w.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3bc64b72cd7f7d383ea8e427c55c6e6e",
     "grade": true,
     "grade_id": "cell-de6575c1f0ae9063",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9d7137345cfbb1ade24d60db982fdd39",
     "grade": false,
     "grade_id": "cell-bdb1eea9979a36a2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 3.2: ( 3 + 9 points )\n",
    "\n",
    "To compute the between cluster covariance, the calculation of the mean of means is necessary. In the function `calc_mean_of_means(clusters)` you must reuse your function `calc_means(clusters)`.\n",
    "\n",
    "\n",
    "* Mean of means: $$\\Large{ \\mu = \\frac{1}{N}\\sum_{C_i \\in \\mathcal{C}}{C_i}},\\quad \\text{where}\\quad N = |\\mathcal{C}|$$\n",
    "\n",
    "\n",
    "The between cluster covariance describes the relation of the datapoints from one cluster to the other. It focuses on the differences rather then the similarities. Use the function `calc_mean_of_means(clusters)` in the function `between_cluster_cov(clusters)` to access the mean of means. **You only have to implement the given formulas**, and do not need to fully understand the underlying concept. \n",
    "\n",
    "* Between cluster covariance: $$\\boxed{\\Large{S_b = \\sum_{k=1}^K  N_k (\\mu_k - \\mu) (\\mu_k - \\mu)^{\\top}}}$$\n",
    "\n",
    "\n",
    "* Number of loops allowed in this exercise: 0 + 1 (one loop only in `between_cluster_cov(clusters)`, to iterate over the clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c8e35454a5bdf6a07d761e50c875d1a0",
     "grade": false,
     "grade_id": "cell-e072ba482ec8f233",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "@no_imports\n",
    "@max_allowed_loops(0)\n",
    "def calc_mean_of_means(clusters: List[np.ndarray]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Given a collection of datapoints divided in clusters, calculate the \n",
    "    mean of all cluster means.\n",
    "    Args:\n",
    "        clusters (List[np.ndarray]): A list of clusters represented in arrays\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: A single datapoint that represents the mean of all the\n",
    "        cluster means\n",
    "        \n",
    "    Example:\n",
    "        >>> calc_mean_of_means(\n",
    "                [np.array([[0.222, 0.333], [0.1, 0.2]]), np.array([[0.8, 0.9], [0.7, 0.5], [0.6, 0.7]])]\n",
    "            )\n",
    "        >>> array([0.4305 , 0.48325])\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError(\"Relplace this line with your code\")\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6a7218a710b214e2c1cce6816be99f57",
     "grade": true,
     "grade_id": "cell-799fb0ebced67cd2",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tiny_result = calc_mean_of_means(\n",
    "    [\n",
    "        np.array([[0.222, 0.333], [0.1, 0.2]]),\n",
    "        np.array([[0.8, 0.9], [0.7, 0.5], [0.6, 0.7]]),\n",
    "    ]\n",
    ")\n",
    "print(tiny_result)\n",
    "tiny_expected = np.array([0.4305, 0.48325])\n",
    "np.testing.assert_allclose(tiny_expected, tiny_result)\n",
    "\n",
    "mean_of_means = calc_mean_of_means(tr_clusters)\n",
    "print(mean_of_means)\n",
    "t.assertIsInstance(mean_of_means, np.ndarray)\n",
    "t.assertEqual(mean_of_means.shape, (2,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bae77188a98b425407ef2c0fb3de9003",
     "grade": true,
     "grade_id": "cell-dfe9f40dc0b31201",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a2a5fbda85f5bb32e7bbdb842e0be324",
     "grade": false,
     "grade_id": "cell-953beace9eeab1ae",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "@no_imports\n",
    "@max_allowed_loops(1)\n",
    "def between_cluster_cov(\n",
    "    clusters: List[np.ndarray], cluster_means: List[np.ndarray], mean_of_means: np.ndarray\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate the covariance between clusters.\n",
    "    \n",
    "    Args:\n",
    "        clusters (List[np.ndarray]): A list of datapoints divided by cluster\n",
    "        cluster_means (List[np.ndarray]): A list of vectors representing the mean\n",
    "        of each cluster\n",
    "        mean_of_means (np.ndarray): A vector, the mean of all datapoints\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Covariance between clusters\n",
    "        \n",
    "    Example: \n",
    "        >>> tiny_clusters = [\n",
    "            np.array([[0.2, 0.3], [0.1, 0.2]]),\n",
    "            np.array([[0.8, 0.9], [0.7, 0.5], [0.6, 0.7]]),\n",
    "        ]\n",
    "        >>> tiny_means = [np.array([0.15, 0.25]), np.array([0.7, 0.7])]\n",
    "        >>> tiny_mean_of_means = np.array([0.425, 0.475])\n",
    "        >>> between_cluster_cov(tiny_clusters, tiny_means, tiny_mean_of_means)\n",
    "        array([[0.378125, 0.309375],\n",
    "               [0.309375, 0.253125]])\n",
    "        \n",
    "    \"\"\"\n",
    "    d = clusters[0].shape[1]\n",
    "    S_b = np.zeros((d, d))\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError(\"Relplace this line with your code\")\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a37fa475f88a30307f214205dce8b64b",
     "grade": true,
     "grade_id": "cell-5ba9704726cfac13",
     "locked": true,
     "points": 9,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tiny_clusters = [\n",
    "    np.array([[0.2, 0.3], [0.1, 0.2]]),\n",
    "    np.array([[0.8, 0.9], [0.7, 0.5], [0.6, 0.7]]),\n",
    "]\n",
    "tiny_means = [np.array([0.15, 0.25]), np.array([0.7, 0.7])]\n",
    "tiny_mean_of_means = np.array([0.425, 0.475])\n",
    "between_cluster_cov(tiny_clusters, tiny_means, tiny_mean_of_means)\n",
    "\n",
    "S_b = between_cluster_cov(tr_clusters, means, mean_of_means)\n",
    "print(S_b)\n",
    "t.assertIsInstance(S_b, np.ndarray)\n",
    "t.assertEqual(S_b.shape, (2, 2))\n",
    "np.testing.assert_allclose(S_b, S_b.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b22987520b737e5d665c5810a58c2b1",
     "grade": true,
     "grade_id": "cell-c586977da962720e",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c5f9971215ce20ef14933fa14320f0c8",
     "grade": false,
     "grade_id": "cell-b8ca981163477312",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 3.3 (14 points):\n",
    "\n",
    "Compute rotation matrix $W$. To find the rotation matrix you first need to find a matrix $A$ so that the within cluster covariance matrix can be transformed into the between cluster covariance matrix. \n",
    "\n",
    "$$\\Large{ S_w A = S_b}$$\n",
    "\n",
    "Next, find the eigenvalues of this matrix $A$. The eigenvectors describe the direction in which the matrix $A$ does _not_ transform and instead only scales. These vectors form the rotation matrix, as they show the directions in which the difference between $S_w$ and $S_b$ is maximized. **Implement the given formulas!**\n",
    "\n",
    "$$ \\Large{AW = \\lambda W}$$\n",
    "* Return the rotation matrix and the index of its biggest axis.\n",
    "\n",
    "\n",
    "* Number of loops allowed in this exercise: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c5b4b737df78771072eddd1ca2562757",
     "grade": false,
     "grade_id": "cell-0e67aa09ec0ad9b4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "@no_imports\n",
    "@max_allowed_loops(0)\n",
    "def rotation_matrix(S_w: np.ndarray, S_b: np.ndarray) -> Tuple[np.ndarray, int]:\n",
    "    \"\"\"\n",
    "    Calculate the transformation matrix given the within- and between cluster\n",
    "    covariance matrices.\n",
    "    \n",
    "    Args:\n",
    "        S_w (np.ndarray): The within cluster covariance\n",
    "        S_b (np.ndarray): The between cluster covariance\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: The transformation matrix\n",
    "        int: The axis along with the transformed data achieves maximal variance\n",
    "        \n",
    "    Example:\n",
    "        >>> tiny_S_w = np.array([[0.025, 0.025], [0.025, 0.085]])\n",
    "        >>> tiny_S_b = np.array([[0.378125, 0.309375], [0.309375, 0.253125]])\n",
    "        >>> rotation_matrix(tiny_S_w, tiny_S_b)\n",
    "        (array([[ 0.99752952, -0.63323779],\n",
    "                [-0.07024856,  0.7739573 ]]), 0)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError(\"Relplace this line with your code\")\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b472a657056135de24d5cc9469c35ec0",
     "grade": true,
     "grade_id": "cell-85f9448ad600c329",
     "locked": true,
     "points": 14,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tiny_S_w = np.array([[0.025, 0.025], [0.025, 0.085]])\n",
    "tiny_S_b = np.array([[0.378125, 0.309375], [0.309375, 0.253125]])\n",
    "tiny_result_M, tiny_result_max_axis = rotation_matrix(tiny_S_w, tiny_S_b)\n",
    "print(tiny_result_M, tiny_result_max_axis)\n",
    "tiny_expected_M, tiny_expected_max_axis = (\n",
    "    np.array([[0.99752952, -0.63323779], [-0.07024856, 0.7739573]]),\n",
    "    0,\n",
    ")\n",
    "np.testing.assert_allclose(tiny_expected_M, tiny_result_M)\n",
    "np.testing.assert_allclose(tiny_expected_max_axis, tiny_result_max_axis)\n",
    "\n",
    "output = rotation_matrix(S_w, S_b)\n",
    "t.assertIsInstance(output, Tuple)\n",
    "t.assertEqual(len(output), 2)\n",
    "W_rot, max_axis = output\n",
    "t.assertIsInstance(W_rot, np.ndarray)\n",
    "t.assertIsInstance(max_axis, np.int64)\n",
    "t.assertEqual(W_rot.shape, (2, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6bad44aae9d2fdcca4ace09e142a2160",
     "grade": true,
     "grade_id": "cell-86885ea99e15a2f6",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "28c4cc5cfd5c8b12f6ad1e996d5ffbbf",
     "grade": false,
     "grade_id": "cell-cd26dbac2c7a4eb5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 3.4: (6  points)\n",
    "\n",
    "Apply rotation matrix to the clusters and return the rotated clusters in a list. \n",
    "\n",
    "* Number of loops allowed in this exercise: 1 (to iterate over the clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d32e221f12b818d10251162a3cbf9050",
     "grade": false,
     "grade_id": "cell-94fb9a3c36466d63",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "@no_imports\n",
    "@max_allowed_loops(1)\n",
    "def rotate_clusters(W_rot: np.ndarray, clusters: List[np.ndarray]) -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Rotate all the datapoints in all the clusters\n",
    "    \n",
    "    Args:\n",
    "        W_rot (np.ndarray): The rotation matrix\n",
    "        clusters (List[np.ndarray]): The list of datapoints divided in clusters that \n",
    "        will be rotated\n",
    "        \n",
    "    Returns: \n",
    "        List[np.ndarray]: The rotated datapoints divided by cluster\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError(\"Relplace this line with your code\")\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d60366c0e7ed8ae76f682101212f787f",
     "grade": true,
     "grade_id": "cell-55865e4e9560a59d",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "rad = np.deg2rad(30)\n",
    "c, s = np.cos(rad), np.sin(rad)\n",
    "rot30 = np.array([[c, -s], [s, c]])\n",
    "tiny_clusters = [\n",
    "    np.array([[0.2, 0.3], [0.1, 0.2]]),\n",
    "    np.array([[0.8, 0.9], [0.7, 0.5], [0.6, 0.7]]),\n",
    "]\n",
    "tiny_rotated_result = rotate_clusters(rot30, tiny_clusters)\n",
    "print(tiny_rotated_result)\n",
    "tiny_rotated_expected = [\n",
    "    np.array([[0.32320508, 0.15980762], [0.18660254, 0.12320508]]),\n",
    "    np.array(\n",
    "        [[1.14282032, 0.37942286], [0.85621778, 0.0830127], [0.86961524, 0.30621778]]\n",
    "    ),\n",
    "]\n",
    "for r, e in zip(tiny_rotated_result, tiny_rotated_expected):\n",
    "    np.testing.assert_allclose(r, e)\n",
    "    \n",
    "rot_tr_clusters = rotate_clusters(W_rot, tr_clusters)\n",
    "t.assertIsInstance(rot_tr_clusters, List)\n",
    "for norm, rotated in zip(tr_clusters, rot_tr_clusters):\n",
    "    t.assertIsInstance(rotated, np.ndarray)\n",
    "    t.assertEqual(norm.shape, rotated.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9bddfba3d9f390a658cd08a8adb8af3a",
     "grade": true,
     "grade_id": "cell-4df38298c0692336",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9ee13ccdd9af75ee844c21ab80c51791",
     "grade": false,
     "grade_id": "cell-da2d1a30341ab871",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Goal\n",
    "\n",
    "Using the rotated clusters, we can now plot the clusters projected onto the axis with highest eigenvalue as histograms. Here we can draw a more accurate line separating the clusters than we could before. This line can be used for classifying data through drawing a simple line between clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4d6783f40a9bfeb26949705dc3c0207e",
     "grade": false,
     "grade_id": "cell-37c9f78313ddfbec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plot_scatter_and_mean(rot_tr_clusters, letters)\n",
    "means = calc_means(rot_tr_clusters)\n",
    "means\n",
    "plot_projection(rot_tr_clusters, letters, means, axis=max_axis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
